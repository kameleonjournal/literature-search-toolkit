{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "06b1d3c1",
   "metadata": {},
   "source": [
    "# NCBI PubMed Literature Search Strategy & CSV Generation\n",
    "This notebook allows you to test different keyword strategies for the NCBI API (using PubMed database)\n",
    "\n",
    "Obtain your API key through your account (optional): https://account.ncbi.nlm.nih.gov/settings/\n",
    "\n",
    "Edit the `groups` and `logic` in the next code cell, then run the subsequent cells to see the results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ae0369f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'requests' is already installed.\n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "import sys\n",
    "\n",
    "try:\n",
    "    import requests\n",
    "    print(\"'requests' is already installed.\")\n",
    "except ModuleNotFoundError:\n",
    "    print(\"'requests' not found. Installing now...\")\n",
    "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"requests\"])\n",
    "    import requests\n",
    "    print(\"'requests' has been installed successfully.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dccda83",
   "metadata": {},
   "source": [
    "# 1. Setup & Define Your Folders and API Key\n",
    "\n",
    "Make sure your .env file is setup with your API key, and output folders. API key for the NCBI API is optional but recommended. You can find a .env.example in "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "12b55d7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Output folders and API key are set up and ready.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "\n",
    "# Load .env variables\n",
    "load_dotenv(find_dotenv())\n",
    "\n",
    "# Get folder paths and API key from environment variables\n",
    "csv_folder = os.getenv(\"CSV_FOLDER\")\n",
    "summary_folder = os.getenv(\"SUMMARY_FOLDER\")\n",
    "api_key = os.getenv(\"YOUR_NCBI_API_KEY\")\n",
    "\n",
    "# This will create the folders (and parents) if they do NOT exist—does nothing if they do\n",
    "os.makedirs(csv_folder, exist_ok=True)\n",
    "os.makedirs(summary_folder, exist_ok=True)\n",
    "\n",
    "# Check that folders and API key are set\n",
    "missing = []\n",
    "if not api_key or api_key == \"YOUR_NCBI_API_KEY\" or api_key == \"your_actual_ncbi_key_here\":\n",
    "    missing.append(\"API key\")\n",
    "if not os.path.isdir(csv_folder):\n",
    "    missing.append(\"CSV folder\")\n",
    "if not os.path.isdir(summary_folder):\n",
    "    missing.append(\"Summary folder\")\n",
    "\n",
    "if missing:\n",
    "    print(f\"⚠️ WARNING: Please check the following: {', '.join(missing)}\")\n",
    "else:\n",
    "    print(\"✅ Output folders and API key are set up and ready.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb40ed6b",
   "metadata": {},
   "source": [
    "# 2. Test and adjust your keyword strategy\n",
    "\n",
    "The below 4 sections will help test different keyword groups and their combinations.\n",
    "- 2.1 Run to define groups of keywords and your exclusion keyword group using AND/OR rules, then define a combination logic\n",
    "- 2.2. Run to see the number of results returned for each keyword group and the combined query\n",
    "- 2.3. Run to see the first 10 titles for each keyword group\n",
    "- 2.4. Run to see the first 10 titles for the combined keyword group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87d22ada",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keyword groups and logic defined.\n",
      "Year filter: 2016:3000[dp]\n",
      "Combined PubMed query: (neuroimaging pipeline OR MRI processing OR neuroinformatics pipeline) AND (structural MRI OR T1-weighted OR T2-weighted OR low-field MRI OR portable MRI) AND (continuous integration OR continuous deployment OR CI/CD OR containerization OR containerisation OR version control OR cloud-based OR serverless OR distributed storage OR BIDS OR flywheel.io OR github OR gitlab OR reproducibility) AND (brain OR neuroimaging) NOT (fMRI OR EEG OR MEG OR functional connectivity OR clinical trial)\n"
     ]
    }
   ],
   "source": [
    "# === EDIT THIS CELL TO CHANGE YEAR RANGE ===\n",
    "year_range = \"2016:3000[dp]\"\n",
    "\n",
    "# === EDIT THIS CELL TO CHANGE KEYWORDS/LOGIC ===\n",
    "groups = {\n",
    "    'group1': 'keyword OR keyword',\n",
    "    'group2': 'keyword OR keyword',\n",
    "    'group3': 'keyword',\n",
    "    'group4': 'keyword',\n",
    "    'excluded': 'NOT (keyword OR keyword)',\n",
    "}\n",
    "\n",
    "logic = \"({group1}) AND ({group2}) AND ({group3}) AND ({group4}) {excluded}\"\n",
    "combined_query = logic.format(**groups)\n",
    "\n",
    "print(f\"Keyword groups and logic defined.\\nYear filter: {year_range}\")\n",
    "print(\"Combined PubMed query:\", combined_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bb033190",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Year limit applied to all queries: 2016:3000[dp]\n",
      "\n",
      "==================================================\n",
      "INDIVIDUAL GROUP RESULTS:\n",
      "==================================================\n",
      "GROUP1                   : 62505 results\n",
      "GROUP2                   : 75448 results\n",
      "GROUP3                   : 363979 results\n",
      "GROUP4                   : 925422 results\n",
      "\n",
      "==================================================\n",
      "COMBINED LOGIC RESULTS:\n",
      "==================================================\n",
      "Logic: ({group1}) AND ({group2}) AND ({group3}) AND ({group4}) {excluded}\n",
      "\n",
      "Combined query: (neuroimaging pipeline OR MRI processing OR neuroinformatics pipeline) AND (structural MRI OR T1-weighted OR T2-weighted OR low-field MRI OR portable MRI) AND (continuous integration OR continuous deployment OR CI/CD OR containerization OR containerisation OR version control OR cloud-based OR serverless OR distributed storage OR BIDS OR flywheel.io OR github OR gitlab OR reproducibility) AND (brain OR neuroimaging) NOT (fMRI OR EEG OR MEG OR functional connectivity OR clinical trial)\n",
      "Combined results: 51\n"
     ]
    }
   ],
   "source": [
    "# === SECTION: Run API Query and Return Total Results for Each Group and Combined Query ===\n",
    "\n",
    "import requests\n",
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "def run_pubmed_query(query, max_results=0, year_range=\"2016:3000[dp]\"):\n",
    "    \"\"\"Run PubMed API query and return count/PMIDs/titles\"\"\"\n",
    "    query_with_year = f\"{query} AND {year_range}\"\n",
    "    params = {\n",
    "        'db': 'pubmed',\n",
    "        'term': query_with_year,\n",
    "        'retmax': max_results or 1,\n",
    "        'retmode': 'xml'\n",
    "    }\n",
    "    esearch_url = \"https://eutils.ncbi.nlm.nih.gov/entrez/eutils/esearch.fcgi\"\n",
    "    esearch_resp = requests.get(esearch_url, params=params)\n",
    "    root = ET.fromstring(esearch_resp.content)\n",
    "    count = int(root.findtext('.//Count', '0'))\n",
    "    pmids = [id_elem.text for id_elem in root.findall('.//Id')]\n",
    "    titles = []\n",
    "    if max_results > 0 and pmids:\n",
    "        efetch_url = \"https://eutils.ncbi.nlm.nih.gov/entrez/eutils/efetch.fcgi\"\n",
    "        efetch_params = {'db': 'pubmed', 'id': ','.join(pmids), 'retmode': 'xml'}\n",
    "        efetch_resp = requests.get(efetch_url, params=efetch_params)\n",
    "        articles = ET.fromstring(efetch_resp.content).findall('.//PubmedArticle')\n",
    "        for article in articles:\n",
    "            title = article.findtext('.//ArticleTitle', default='').replace('\\n', ' ').strip()\n",
    "            titles.append(title)\n",
    "    return count, pmids, titles\n",
    "\n",
    "# Print year filter info\n",
    "print(f\"Year limit applied to all queries: {year_range}\\n\")\n",
    "\n",
    "# Test individual keyword groups\n",
    "print(\"=\"*50)\n",
    "print(\"INDIVIDUAL GROUP RESULTS:\")\n",
    "print(\"=\"*50)\n",
    "for name, query in groups.items():\n",
    "    if name != 'excluded':  # Skip exclusion group\n",
    "        count, _, _ = run_pubmed_query(query)\n",
    "        print(f\"{name.upper():<25}: {count} results\")\n",
    "\n",
    "# Print combined query\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"COMBINED LOGIC RESULTS:\")\n",
    "print(\"=\"*50)\n",
    "print(f\"Logic: {logic}\\n\")\n",
    "print(f\"Combined query: {combined_query}\")\n",
    "combined_count, pmids, _ = run_pubmed_query(combined_query)\n",
    "print(f\"Combined results: {combined_count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd04045b",
   "metadata": {},
   "source": [
    "The next block will show the first 10 titles for each keyword group (except the excluded keyword group).\n",
    "\n",
    "Based on this, you can go back and adust your keyword groups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e28fd501",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "FIRST 10 TITLES FOR GROUP: GROUP1\n",
      "==================================================\n",
      "1. Comparison of two preprocessing methods for\n",
      "2. Mediating role of feeder connections in the relationship between brain network efficiency and episodic memory in amnestic MCI.\n",
      "3. Breaking data silos: incorporating the DICOM imaging standard into the OMOP CDM to enable multimodal research.\n",
      "4. Real-time color flow mapping of ultrasound microrobots.\n",
      "5. An Automatic 3D PET Tumor Segmentation Framework Assisted by Geodesic Sequences.\n",
      "6. High-resolution 3D whole-heart bright- and black-blood imaging with co-registered T2 mapping at 0.55 T.\n",
      "7. Higher-order Sonification of the Human Brain.\n",
      "8. Mitigating Organophosphate Nerve Agent, Soman (GD)-Induced Long-Term Neurotoxicity: Saracatinib, a Src Tyrosine Kinase Inhibitor, as a Potential Countermeasure.\n",
      "9. Frequency of autoimmune-associated exogenous psychoses in routine clinical care.\n",
      "10. GABA, Glx, and GSH in the cerebellum: their role in motor performance and learning across age groups.\n",
      "\n",
      "==================================================\n",
      "FIRST 10 TITLES FOR GROUP: GROUP2\n",
      "==================================================\n",
      "1. Case Series of 46 Patients with Nonketotic Hyperglycemia-Associated Chorea: A Retrospective Follow-Up Study.\n",
      "2. Predictive Factors of Malignancy in Cervical Paragangliomas: A Retrospective Study.\n",
      "3. Functional-structural co-dependent brain mapping of metamemory in amnestic mild cognitive impairment.\n",
      "4. AI-Driven segmentation and morphogeometric profiling of epicardial adipose tissue in type 2 diabetes.\n",
      "5. Individualized transcranial temporal interference stimulation (tTIS) for cognitive impairments and negative symptoms in patients with schizophrenia: a study protocol for a randomized controlled trial.\n",
      "6. A pattern-learning algorithm associates copy number variations with brain structure and behavioural variables in an adolescent population cohort.\n",
      "7. Tenosynovial giant cell tumor and its differential diagnosis in children.\n",
      "8. Diagnostic interchangeability of deep-learning based Synth-STIR images generated from T1 and T2 weighted spine images.\n",
      "9. Immunosenescence-related T cell phenotypes, structural brain imaging, and cognitive impairment in patients with schizophrenia: a moderated mediation analysis.\n",
      "10. Regions of Interest Assessment of Prenatal Exposure to Tobacco on Adolescent Cortical Thickness and Sulcal Depth.\n",
      "\n",
      "==================================================\n",
      "FIRST 10 TITLES FOR GROUP: GROUP3\n",
      "==================================================\n",
      "1. Adaptation of the Medical Student Stress Factor Scale Into Turkish: Validity and Reliability Study.\n",
      "2. Sleep Medicine-What's in a Name?\n",
      "3. Emerging Role of MRI-Based Artificial Intelligence in Individualized Treatment Strategies for Hepatocellular Carcinoma: A Narrative Review.\n",
      "4. Accuracy and Time Efficiency of Artificial Intelligence-Driven Tooth Segmentation on CBCT Images: A Validation Study Using Two Implant Planning Software Programs.\n",
      "5. Formic Acid Electroreduction Pathways on (111) Metal Surfaces.\n",
      "6. Network Analysis of Anxiety in Prostate Cancer Patients.\n",
      "7. Psychometric properties of the Warwick Edinburgh Mental Well-being Scale: a systematic review.\n",
      "8. REVERSE model: a novel approach in medical research.\n",
      "9. Nursing and midwifery students' perceptions of sign language training in Ghana: relevance, instructional methods, and assessment practices.\n",
      "10. A global living systematic review and meta-analysis hub of emerging vaccines in pregnancy and childhood.\n",
      "\n",
      "==================================================\n",
      "FIRST 10 TITLES FOR GROUP: GROUP4\n",
      "==================================================\n",
      "1. AMPK regulates pupal diapause by modulating glucose metabolism in the brain of the cotton bollworm, Helicoverpa armigera.\n",
      "2. Case Series of 46 Patients with Nonketotic Hyperglycemia-Associated Chorea: A Retrospective Follow-Up Study.\n",
      "3. Status and Prospects of Glioblastoma Multiforme Treatments.\n",
      "4. Unveiling the Molecular Pathogenesis of MCPH: Insights From Drosophila Model System.\n",
      "5. Individualised Alpha-tACS for Modulating Pain Perception and Neural Oscillations: A Sham-Controlled Study in Healthy Participants.\n",
      "6. Maternal Tryptophan Supplementation Alters Offspring Gut-Brain Axis and Behavior in a Sex-Specific Manner.\n",
      "7. Characterizing fetoplacental response to acute maternal hyperoxygenation in suspected coarctation of aorta using fetal cardiac MRI.\n",
      "8. Drug Exposure in Chronic Kidney Disease: It Is Not Just About the Glomerular Filtration Rate.\n",
      "9. AAV-delivered PPT1 provides long-term neurological benefits in CLN1 mice and achieves therapeutic levels in sheep brain.\n",
      "10. Adult Hemophagocytic Lymphohistiocytosis (HLH) with Neurological Involvement: Diagnostic Complexities - A Case Report and Literature Review.\n"
     ]
    }
   ],
   "source": [
    "# === SECTION: Print First 10 Titles for Each Group (Excluding 'excluded') ===\n",
    "\n",
    "max_titles = 10  # Number of titles to print for each group\n",
    "\n",
    "for name, query in groups.items():\n",
    "    if name != 'excluded':\n",
    "        print(\"\\n\" + \"=\"*50)\n",
    "        print(f\"FIRST {max_titles} TITLES FOR GROUP: {name.upper()}\")\n",
    "        print(\"=\"*50)\n",
    "        count, pmids, titles = run_pubmed_query(query, max_results=max_titles, year_range=year_range)\n",
    "        if titles:\n",
    "            for i, title in enumerate(titles, 1):\n",
    "                print(f\"{i}. {title}\")\n",
    "        else:\n",
    "            print(\"No titles found for this group.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14de2937",
   "metadata": {},
   "source": [
    "The next block will show the first 10 titles for the combined query.\n",
    "\n",
    "Based on the results you can go back and adjust your groups and logic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f5d8febb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "FIRST 10 TITLES FOR COMBINED QUERY:\n",
      "==================================================\n",
      "1. Region-based U-nets for fast, accurate, and scalable deep brain segmentation: Application to Parkinson Plus Syndromes.\n",
      "2. Normative range of MRI-derived fetal brain volume throughout gestation: a prospective study.\n",
      "3. fMRIPrep Lifespan: Extending A Robust Pipeline for Functional MRI Preprocessing to Developmental Neuroimaging.\n",
      "4. Recent advances in the detection and management of motor dysfunction in Alzheimer's disease.\n",
      "5. Evaluating the Quality of Brain MRI Generators.\n",
      "6. Modular strategies for spatial mapping of diverse cell type data of the mouse brain.\n",
      "7. FastSurfer-LIT: Lesion inpainting tool for whole-brain MRI segmentation with tumors, cavities, and abnormalities.\n",
      "8. Host genetics maps to behaviour and brain structure in developmental mice.\n",
      "9. A New Tool for Extracting Static and Dynamic Parameters from [\n",
      "10. Quantitative reliability assessment of brain MRI volumetric measurements in type II GM1 gangliosidosis patients.\n"
     ]
    }
   ],
   "source": [
    "# === SECTION: Show First 10 Titles for Combined Keyword Group ===\n",
    "\n",
    "max_titles_to_print = 10 # <-- Adjust this if you want more or fewer\n",
    "\n",
    "# Fetch results and titles\n",
    "combined_count, _, _ = run_pubmed_query(combined_query, max_results=0, year_range=year_range)\n",
    "\n",
    "if combined_count > 0:\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(f\"FIRST {max_titles_to_print} TITLES FOR COMBINED QUERY:\")\n",
    "    print(\"=\"*50)\n",
    "    _, _, titles = run_pubmed_query(combined_query, max_results=max_titles_to_print, year_range=year_range)\n",
    "    for i, title in enumerate(titles, 1):\n",
    "        print(f\"{i}. {title}\")\n",
    "else:\n",
    "    print(\"\\nNo results found for the combined query.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "011b84a3",
   "metadata": {},
   "source": [
    "# 2. Export PubMed Results to CSV\n",
    "\n",
    "The below script will use your combined query to download titles and abstracts and save them to a CSV file, including author name, title, abstract, year and doi. It will also update the summary table to include the total of found and downloaded records, the source the final query and a timestamp for record keeping purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fa622120",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Querying PubMed for: (neuroimaging pipeline OR MRI processing OR neuroinformatics pipeline) AND (structural MRI OR T1-weighted OR T2-weighted OR low-field MRI OR portable MRI) AND (continuous integration OR continuous deployment OR CI/CD OR containerization OR containerisation OR version control OR cloud-based OR serverless OR distributed storage OR BIDS OR flywheel.io OR github OR gitlab OR reproducibility) AND (brain OR neuroimaging) NOT (fMRI OR EEG OR MEG OR functional connectivity OR clinical trial) AND 2016:3000[dp]\n",
      "Retrieved 51 PubMed IDs\n",
      "Writing results to CSV: C:/Users/petra/Documents/UniKCL/Workshop/csvs/pubmed_v1.csv\n",
      "Downloaded 51 records to C:/Users/petra/Documents/UniKCL/Workshop/csvs/pubmed_v1.csv\n",
      "Summary row added for pubmed_v1\n"
     ]
    }
   ],
   "source": [
    "# === SECTION: Download CSV and Update Summary ===\n",
    "\n",
    "# === SECTION: IMPORTS ===\n",
    "import os\n",
    "import csv\n",
    "import requests\n",
    "import xml.etree.ElementTree as ET\n",
    "from datetime import datetime\n",
    "\n",
    "# === SECTION: UTILITY FUNCTION: Get Next CSV Name ===\n",
    "def get_next_csv_name(folder, base_name):\n",
    "    i = 1\n",
    "    while True:\n",
    "        csv_name = f\"{base_name}_v{i}.csv\"\n",
    "        csv_path = os.path.join(folder, csv_name)\n",
    "        if not os.path.exists(csv_path):\n",
    "            return f\"{base_name}_v{i}\", csv_path  # returns base name for summary and full path\n",
    "        i += 1\n",
    "\n",
    "# === SECTION: MAIN FUNCTION: Download PubMed Results to CSV ===\n",
    "def download_ncbi_to_csv(query, csv_folder, api_key, year_range, max_results=None):\n",
    "    os.makedirs(csv_folder, exist_ok=True)\n",
    "    esearch_url = \"https://eutils.ncbi.nlm.nih.gov/entrez/eutils/esearch.fcgi\"\n",
    "    efetch_url = \"https://eutils.ncbi.nlm.nih.gov/entrez/eutils/efetch.fcgi\"\n",
    "\n",
    "    query_with_year = f\"{query} AND {year_range}\"\n",
    "    params = {\n",
    "        'db': 'pubmed',\n",
    "        'term': query_with_year,\n",
    "        'retmax': max_results if max_results is not None else 10000,\n",
    "        'retmode': 'xml',\n",
    "        'api_key': api_key\n",
    "    }\n",
    "    print(f\"Querying PubMed for: {query_with_year}\")\n",
    "    esearch_resp = requests.get(esearch_url, params=params)\n",
    "    root = ET.fromstring(esearch_resp.content)\n",
    "    ids = [id_elem.text for id_elem in root.findall('.//Id')]\n",
    "    print(f\"Retrieved {len(ids)} PubMed IDs\")\n",
    "\n",
    "    base_name, csv_path = get_next_csv_name(csv_folder, \"pubmed\")\n",
    "    print(f\"Writing results to CSV: {csv_path}\")\n",
    "\n",
    "    count_downloaded = 0\n",
    "    with open(csv_path, 'w', newline='', encoding='utf-8') as csvfile:\n",
    "        writer = csv.writer(csvfile)\n",
    "        writer.writerow(['first_author', 'all_authors', 'title', 'abstract', 'year', 'doi'])\n",
    "\n",
    "        if ids:\n",
    "            efetch_params = {\n",
    "                'db': 'pubmed',\n",
    "                'id': ','.join(ids),\n",
    "                'retmode': 'xml',\n",
    "                'api_key': api_key\n",
    "            }\n",
    "            efetch_resp = requests.get(efetch_url, params=efetch_params)\n",
    "            root = ET.fromstring(efetch_resp.content)\n",
    "\n",
    "            for article in root.findall('.//PubmedArticle'):\n",
    "                authors = []\n",
    "                first_author = ''\n",
    "                author_list = article.find('.//AuthorList')\n",
    "                if author_list is not None:\n",
    "                    for i, author in enumerate(author_list.findall('Author')):\n",
    "                        last = author.findtext('LastName', default='')\n",
    "                        fore = author.findtext('ForeName', default='')\n",
    "                        full_name = f\"{fore} {last}\".strip()\n",
    "                        if full_name:\n",
    "                            authors.append(full_name)\n",
    "                        if i == 0 and full_name:\n",
    "                            first_author = full_name\n",
    "                all_authors = '; '.join(authors)\n",
    "\n",
    "                title = article.findtext('.//ArticleTitle', default='').replace('\\n', ' ').strip()\n",
    "\n",
    "                abstract = ''\n",
    "                abstract_elem = article.find('.//Abstract')\n",
    "                if abstract_elem is not None:\n",
    "                    abstract = ' '.join([abst.text for abst in abstract_elem.findall('AbstractText') if abst.text]).replace('\\n', ' ').strip()\n",
    "\n",
    "                year = ''\n",
    "                pubdate = article.find('.//Journal/JournalIssue/PubDate/Year')\n",
    "                if pubdate is not None:\n",
    "                    year = pubdate.text\n",
    "                else:\n",
    "                    year = article.findtext('.//Article/Journal/JournalIssue/PubDate/Year', default='')\n",
    "                year = year.strip() if year else ''\n",
    "\n",
    "                doi = article.findtext('.//ArticleId[@IdType=\"doi\"]', default='')\n",
    "\n",
    "                writer.writerow([first_author, all_authors, title, abstract, year, doi])\n",
    "                count_downloaded += 1\n",
    "\n",
    "    print(f\"Downloaded {count_downloaded} records to {csv_path}\")\n",
    "    # Capture timestamp at end of download in ISO format without seconds\n",
    "    timestamp = datetime.now().strftime(\"%Y-%m-%dT%H:%M\")\n",
    "    return len(ids), count_downloaded, base_name, timestamp  # <--- return timestamp\n",
    "\n",
    "# === SECTION: SUMMARY ROW APPEND WITH TIMESTAMP ===\n",
    "def append_summary_row(summary_folder, base_name, found, downloaded, query, timestamp):\n",
    "    summary_csv_path = os.path.join(summary_folder, \"summary_csv.csv\")\n",
    "    os.makedirs(summary_folder, exist_ok=True)\n",
    "    header = \"source,found,downloaded,query combination,timestamp\\n\"\n",
    "    row = f\"{base_name},{found},{downloaded},\\\"{query}\\\",{timestamp}\\n\"\n",
    "\n",
    "    # Check if file exists and if it's empty\n",
    "    file_exists = os.path.exists(summary_csv_path)\n",
    "    is_empty = not file_exists or os.path.getsize(summary_csv_path) == 0\n",
    "\n",
    "    with open(summary_csv_path, 'a', encoding='utf-8', newline='') as f:\n",
    "        if is_empty:\n",
    "            f.write(header)\n",
    "        f.write(row)\n",
    "    print(f\"Summary row added for {base_name}\")\n",
    "\n",
    "# === SECTION: RUN DOWNLOAD AND SUMMARY ===\n",
    "found, downloaded, base_name, timestamp = download_ncbi_to_csv(\n",
    "    combined_query,\n",
    "    csv_folder,\n",
    "    api_key,\n",
    "    year_range=year_range,\n",
    "    max_results=None  # Change to None to download all results\n",
    ")\n",
    "\n",
    "append_summary_row(\n",
    "    summary_folder,\n",
    "    base_name,\n",
    "    found=found,\n",
    "    downloaded=downloaded,\n",
    "    query=combined_query,\n",
    "    timestamp=timestamp\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
