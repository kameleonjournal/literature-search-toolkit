{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "06b1d3c1",
   "metadata": {},
   "source": [
    "# NCBI PubMed Literature Search Strategy & CSV Generation\n",
    "This notebook allows you to test different keyword strategies for the NCBI API (using PubMed database)\n",
    "\n",
    "Obtain your API key through your account (optional): https://account.ncbi.nlm.nih.gov/settings/\n",
    "\n",
    "Edit the `groups` and `logic` in the next code cell, then run the subsequent cells to see the results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae0369f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import sys\n",
    "\n",
    "try:\n",
    "    import requests\n",
    "    print(\"'requests' is already installed.\")\n",
    "except ModuleNotFoundError:\n",
    "    print(\"'requests' not found. Installing now...\")\n",
    "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"requests\"])\n",
    "    import requests\n",
    "    print(\"'requests' has been installed successfully.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dccda83",
   "metadata": {},
   "source": [
    "# 1. Setup & Define Your Folders and API Key\n",
    "\n",
    "In the below section uncomment (ctrl+/ on PC or command+/ on Mac) the relevant lines to define the csv and summary folder and to include your API key. API key for the NCBI API is optional but recommended"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "228ec081",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === SECTION: USER SETUP (PC/Windows) ===\n",
    "# Uncomment below and edit these variables to match your Windows setup\n",
    "# csv_folder = r\"C:\\Users\\YOUR_USERNAME\\Documents\\csvs\\pubmed_csv\"\n",
    "# summary_folder = r\"C:\\Users\\YOUR_USERNAME\\Documents\\csvs\\summaries\"\n",
    "# api_key = \"YOUR_NCBI_API_KEY\"  # Replace with your NCBI API key\n",
    "\n",
    "# === SECTION: USER SETUP (Mac) ===\n",
    "# Uncomment below and edit these lines to match your Mac setup\n",
    "csv_folder = r\"/Users/YOUR_USERNAME/Documents/csvs/pubmed_csv\"\n",
    "summary_folder = r\"/Users/YOUR_USERNAME/Documents/csvs/summaries\"\n",
    "api_key = \"YOUR_NCBI_API_KEY\"  # Replace with your NCBI API key (https://developer.ieee.org/)\n",
    "\n",
    "# === SECTION: FOLDER CREATION AND CHECK ===\n",
    "import os\n",
    "\n",
    "os.makedirs(csv_folder, exist_ok=True)\n",
    "os.makedirs(summary_folder, exist_ok=True)\n",
    "missing = []\n",
    "if not api_key or api_key == \"YOUR_NCBI_API_KEY\":\n",
    "    missing.append(\"API key\")\n",
    "if not os.path.isdir(csv_folder):\n",
    "    missing.append(\"CSV folder\")\n",
    "if not os.path.isdir(summary_folder):\n",
    "    missing.append(\"Summary folder\")\n",
    "\n",
    "if missing:\n",
    "    print(f\"⚠️ WARNING: Please check the following: {', '.join(missing)}\")\n",
    "else:\n",
    "    print(\"✅ Output folders and API key are set up and ready.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb40ed6b",
   "metadata": {},
   "source": [
    "# 2. Test and adjust your keyword strategy\n",
    "\n",
    "The below 4 sections will help test different keyword groups and their combinations.\n",
    "- 2.1 Run to define groups of keywords and your exclusion keyword group using AND/OR rules, then define a combination logic\n",
    "- 2.2. Run to see the number of results returned for each keyword group and the combined query\n",
    "- 2.3. Run to see the first 10 titles for each keyword group\n",
    "- 2.4. Run to see the first 10 titles for the combined keyword group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87d22ada",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === EDIT THIS CELL TO CHANGE YEAR RANGE ===\n",
    "year_range = \"2016:3000[dp]\"\n",
    "\n",
    "# === EDIT THIS CELL TO CHANGE KEYWORDS/LOGIC ===\n",
    "groups = {\n",
    "    'group1': 'keyword OR keyword',\n",
    "    'group2': 'keyword OR keyword AND keyword',\n",
    "    'excluded': 'NOT (keyword or keyword)'\n",
    "}\n",
    "\n",
    "logic = \"({group1}) AND ({group2}) {excluded}\"\n",
    "combined_query = logic.format(**groups)\n",
    "\n",
    "print(f\"Keyword groups and logic defined.\\nYear filter: {year_range}\")\n",
    "print(\"Combined PubMed query:\", combined_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb033190",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === SECTION: Run API Query and Return Total Results for Each Group and Combined Query ===\n",
    "\n",
    "import requests\n",
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "def run_pubmed_query(query, max_results=0, year_range=\"2016:3000[dp]\"):\n",
    "    \"\"\"Run PubMed API query and return count/PMIDs/titles\"\"\"\n",
    "    query_with_year = f\"{query} AND {year_range}\"\n",
    "    params = {\n",
    "        'db': 'pubmed',\n",
    "        'term': query_with_year,\n",
    "        'retmax': max_results or 1,\n",
    "        'retmode': 'xml'\n",
    "    }\n",
    "    esearch_url = \"https://eutils.ncbi.nlm.nih.gov/entrez/eutils/esearch.fcgi\"\n",
    "    esearch_resp = requests.get(esearch_url, params=params)\n",
    "    root = ET.fromstring(esearch_resp.content)\n",
    "    count = int(root.findtext('.//Count', '0'))\n",
    "    pmids = [id_elem.text for id_elem in root.findall('.//Id')]\n",
    "    titles = []\n",
    "    if max_results > 0 and pmids:\n",
    "        efetch_url = \"https://eutils.ncbi.nlm.nih.gov/entrez/eutils/efetch.fcgi\"\n",
    "        efetch_params = {'db': 'pubmed', 'id': ','.join(pmids), 'retmode': 'xml'}\n",
    "        efetch_resp = requests.get(efetch_url, params=efetch_params)\n",
    "        articles = ET.fromstring(efetch_resp.content).findall('.//PubmedArticle')\n",
    "        for article in articles:\n",
    "            title = article.findtext('.//ArticleTitle', default='').replace('\\n', ' ').strip()\n",
    "            titles.append(title)\n",
    "    return count, pmids, titles\n",
    "\n",
    "# Print year filter info\n",
    "print(f\"Year limit applied to all queries: {year_range}\\n\")\n",
    "\n",
    "# Test individual keyword groups\n",
    "print(\"=\"*50)\n",
    "print(\"INDIVIDUAL GROUP RESULTS:\")\n",
    "print(\"=\"*50)\n",
    "for name, query in groups.items():\n",
    "    if name != 'excluded':  # Skip exclusion group\n",
    "        count, _, _ = run_pubmed_query(query)\n",
    "        print(f\"{name.upper():<25}: {count} results\")\n",
    "\n",
    "# Print combined query\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"COMBINED LOGIC RESULTS:\")\n",
    "print(\"=\"*50)\n",
    "print(f\"Logic: {logic}\\n\")\n",
    "print(f\"Combined query: {combined_query}\")\n",
    "combined_count, pmids, _ = run_pubmed_query(combined_query)\n",
    "print(f\"Combined results: {combined_count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd04045b",
   "metadata": {},
   "source": [
    "The next block will show the first 10 titles for each keyword group (except the excluded keyword group).\n",
    "\n",
    "Based on this, you can go back and adust your keyword groups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e28fd501",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === SECTION: Print First 10 Titles for Each Group (Excluding 'excluded') ===\n",
    "\n",
    "max_titles = 10  # Number of titles to print for each group\n",
    "\n",
    "for name, query in groups.items():\n",
    "    if name != 'excluded':\n",
    "        print(\"\\n\" + \"=\"*50)\n",
    "        print(f\"FIRST {max_titles} TITLES FOR GROUP: {name.upper()}\")\n",
    "        print(\"=\"*50)\n",
    "        count, pmids, titles = run_pubmed_query(query, max_results=max_titles, year_range=year_range)\n",
    "        if titles:\n",
    "            for i, title in enumerate(titles, 1):\n",
    "                print(f\"{i}. {title}\")\n",
    "        else:\n",
    "            print(\"No titles found for this group.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14de2937",
   "metadata": {},
   "source": [
    "The next block will show the first 10 titles for the combined query.\n",
    "\n",
    "Based on the results you can go back and adjust your groups and logic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5d8febb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === SECTION: Show First 10 Titles for Combined Keyword Group ===\n",
    "\n",
    "max_titles_to_print = 10 # <-- Adjust this if you want more or fewer\n",
    "\n",
    "# Fetch results and titles\n",
    "combined_count, _, _ = run_pubmed_query(combined_query, max_results=0, year_range=year_range)\n",
    "\n",
    "if combined_count > 0:\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(f\"FIRST {max_titles_to_print} TITLES FOR COMBINED QUERY:\")\n",
    "    print(\"=\"*50)\n",
    "    _, _, titles = run_pubmed_query(combined_query, max_results=max_titles_to_print, year_range=year_range)\n",
    "    for i, title in enumerate(titles, 1):\n",
    "        print(f\"{i}. {title}\")\n",
    "else:\n",
    "    print(\"\\nNo results found for the combined query.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "011b84a3",
   "metadata": {},
   "source": [
    "# 2. Export PubMed Results to CSV\n",
    "\n",
    "The below script will use your combined query to download titles and abstracts and save them to a CSV file, including author name, title, abstract, year and doi. It will also update the summary table to include the total of found and downloaded records, the source the final query and a timestamp for record keeping purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa622120",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === SECTION: Download CSV and Update Summary ===\n",
    "\n",
    "# === SECTION: IMPORTS ===\n",
    "import os\n",
    "import csv\n",
    "import requests\n",
    "import xml.etree.ElementTree as ET\n",
    "from datetime import datetime\n",
    "\n",
    "# === SECTION: UTILITY FUNCTION: Get Next CSV Name ===\n",
    "def get_next_csv_name(folder, base_name):\n",
    "    i = 1\n",
    "    while True:\n",
    "        csv_name = f\"{base_name}_v{i}.csv\"\n",
    "        csv_path = os.path.join(folder, csv_name)\n",
    "        if not os.path.exists(csv_path):\n",
    "            return f\"{base_name}_v{i}\", csv_path  # returns base name for summary and full path\n",
    "        i += 1\n",
    "\n",
    "# === SECTION: MAIN FUNCTION: Download PubMed Results to CSV ===\n",
    "def download_ncbi_to_csv(query, csv_folder, api_key, year_range, max_results=None):\n",
    "    os.makedirs(csv_folder, exist_ok=True)\n",
    "    esearch_url = \"https://eutils.ncbi.nlm.nih.gov/entrez/eutils/esearch.fcgi\"\n",
    "    efetch_url = \"https://eutils.ncbi.nlm.nih.gov/entrez/eutils/efetch.fcgi\"\n",
    "\n",
    "    query_with_year = f\"{query} AND {year_range}\"\n",
    "    params = {\n",
    "        'db': 'pubmed',\n",
    "        'term': query_with_year,\n",
    "        'retmax': max_results if max_results is not None else 10000,\n",
    "        'retmode': 'xml',\n",
    "        'api_key': api_key\n",
    "    }\n",
    "    print(f\"Querying PubMed for: {query_with_year}\")\n",
    "    esearch_resp = requests.get(esearch_url, params=params)\n",
    "    root = ET.fromstring(esearch_resp.content)\n",
    "    ids = [id_elem.text for id_elem in root.findall('.//Id')]\n",
    "    print(f\"Retrieved {len(ids)} PubMed IDs\")\n",
    "\n",
    "    base_name, csv_path = get_next_csv_name(csv_folder, \"pubmed\")\n",
    "    print(f\"Writing results to CSV: {csv_path}\")\n",
    "\n",
    "    count_downloaded = 0\n",
    "    with open(csv_path, 'w', newline='', encoding='utf-8') as csvfile:\n",
    "        writer = csv.writer(csvfile)\n",
    "        writer.writerow(['first_author', 'all_authors', 'title', 'abstract', 'year', 'doi'])\n",
    "\n",
    "        if ids:\n",
    "            efetch_params = {\n",
    "                'db': 'pubmed',\n",
    "                'id': ','.join(ids),\n",
    "                'retmode': 'xml',\n",
    "                'api_key': api_key\n",
    "            }\n",
    "            efetch_resp = requests.get(efetch_url, params=efetch_params)\n",
    "            root = ET.fromstring(efetch_resp.content)\n",
    "\n",
    "            for article in root.findall('.//PubmedArticle'):\n",
    "                authors = []\n",
    "                first_author = ''\n",
    "                author_list = article.find('.//AuthorList')\n",
    "                if author_list is not None:\n",
    "                    for i, author in enumerate(author_list.findall('Author')):\n",
    "                        last = author.findtext('LastName', default='')\n",
    "                        fore = author.findtext('ForeName', default='')\n",
    "                        full_name = f\"{fore} {last}\".strip()\n",
    "                        if full_name:\n",
    "                            authors.append(full_name)\n",
    "                        if i == 0 and full_name:\n",
    "                            first_author = full_name\n",
    "                all_authors = '; '.join(authors)\n",
    "\n",
    "                title = article.findtext('.//ArticleTitle', default='').replace('\\n', ' ').strip()\n",
    "\n",
    "                abstract = ''\n",
    "                abstract_elem = article.find('.//Abstract')\n",
    "                if abstract_elem is not None:\n",
    "                    abstract = ' '.join([abst.text for abst in abstract_elem.findall('AbstractText') if abst.text]).replace('\\n', ' ').strip()\n",
    "\n",
    "                year = ''\n",
    "                pubdate = article.find('.//Journal/JournalIssue/PubDate/Year')\n",
    "                if pubdate is not None:\n",
    "                    year = pubdate.text\n",
    "                else:\n",
    "                    year = article.findtext('.//Article/Journal/JournalIssue/PubDate/Year', default='')\n",
    "                year = year.strip() if year else ''\n",
    "\n",
    "                doi = article.findtext('.//ArticleId[@IdType=\"doi\"]', default='')\n",
    "\n",
    "                writer.writerow([first_author, all_authors, title, abstract, year, doi])\n",
    "                count_downloaded += 1\n",
    "\n",
    "    print(f\"Downloaded {count_downloaded} records to {csv_path}\")\n",
    "    # Capture timestamp at end of download in ISO format without seconds\n",
    "    timestamp = datetime.now().strftime(\"%Y-%m-%dT%H:%M\")\n",
    "    return len(ids), count_downloaded, base_name, timestamp  # <--- return timestamp\n",
    "\n",
    "# === SECTION: SUMMARY ROW APPEND WITH TIMESTAMP ===\n",
    "def append_summary_row(summary_folder, base_name, found, downloaded, query, timestamp):\n",
    "    summary_csv_path = os.path.join(summary_folder, \"summary_csv.csv\")\n",
    "    os.makedirs(summary_folder, exist_ok=True)\n",
    "    header = \"source,found,downloaded,query combination,timestamp\\n\"\n",
    "    row = f\"{base_name},{found},{downloaded},\\\"{query}\\\",{timestamp}\\n\"\n",
    "\n",
    "    # Check if file exists and if it's empty\n",
    "    file_exists = os.path.exists(summary_csv_path)\n",
    "    is_empty = not file_exists or os.path.getsize(summary_csv_path) == 0\n",
    "\n",
    "    with open(summary_csv_path, 'a', encoding='utf-8', newline='') as f:\n",
    "        if is_empty:\n",
    "            f.write(header)\n",
    "        f.write(row)\n",
    "    print(f\"Summary row added for {base_name}\")\n",
    "\n",
    "# === SECTION: RUN DOWNLOAD AND SUMMARY ===\n",
    "found, downloaded, base_name, timestamp = download_ncbi_to_csv(\n",
    "    combined_query,\n",
    "    csv_folder,\n",
    "    api_key,\n",
    "    year_range=year_range,\n",
    "    max_results=None  # Change to None to download all results\n",
    ")\n",
    "\n",
    "append_summary_row(\n",
    "    summary_folder,\n",
    "    base_name,\n",
    "    found=found,\n",
    "    downloaded=downloaded,\n",
    "    query=combined_query,\n",
    "    timestamp=timestamp\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
